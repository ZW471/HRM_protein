{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-22T07:46:33.513376Z",
     "start_time": "2025-09-22T07:46:33.500646Z"
    }
   },
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        scores = (torch.bmm(q, k.transpose(-2, -1)))\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float(\"-inf\"))\n",
    "        # print(self.softmax(\n",
    "        #     scores / torch.sqrt(torch.tensor(k.shape[-1]))\n",
    "        # ))\n",
    "        return torch.bmm(self.softmax(\n",
    "            scores / torch.sqrt(torch.tensor(k.shape[-1]))\n",
    "        ), v)\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, dim_in, dim_qk, dim_v, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.W_q = nn.Linear(dim_in, dim_qk, bias=False)\n",
    "        self.W_k = nn.Linear(dim_in, dim_qk, bias=False)\n",
    "        self.W_v = nn.Linear(dim_in, dim_v, bias=False)\n",
    "        self.attention = Attention()\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        q = self.W_q(x)\n",
    "        k = self.W_k(x)\n",
    "        v = self.W_v(x)\n",
    "\n",
    "        print(f\"q: {q.shape}, k: {k.shape}, v: {v.shape}\")\n",
    "\n",
    "        return self.attention(q, k, v, mask=mask)\n",
    "\n",
    "def causal_mask(T: int, device=None, dtype=torch.bool):\n",
    "    # True above the diagonal â‡’ blocked\n",
    "    return torch.triu(torch.ones(T, T, dtype=dtype, device=device), diagonal=1).bool()\n",
    "\n",
    "att = ScaledDotProductAttention(\n",
    "    dim_in=8,\n",
    "    dim_qk=6,\n",
    "    dim_v=4,\n",
    ")\n",
    "\n",
    "sample_x = torch.randn(4, 5, 8)\n",
    "res = att(sample_x, mask=causal_mask(sample_x.shape[-2]))\n",
    "print(f\"res: {res}, shape: {res.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: torch.Size([4, 5, 6]), k: torch.Size([4, 5, 6]), v: torch.Size([4, 5, 4])\n",
      "res: tensor([[[ 3.4839e-01,  2.0837e-03,  4.5356e-01,  5.5659e-01],\n",
      "         [-1.8473e-01, -8.1765e-02,  2.6405e-01,  2.1737e-01],\n",
      "         [-3.7273e-01, -1.5326e-02,  1.1574e-03,  4.6656e-02],\n",
      "         [-4.6438e-01,  1.6161e-02, -3.0954e-01,  1.7121e-01],\n",
      "         [-5.8848e-01,  2.1596e-01, -4.2419e-01, -1.2902e-02]],\n",
      "\n",
      "        [[-2.9526e-02,  2.8245e-01, -1.8785e-01,  1.3996e-01],\n",
      "         [ 3.0942e-01, -4.7385e-02, -8.8221e-02,  5.4484e-02],\n",
      "         [ 4.5246e-01, -3.5625e-01,  4.4135e-01,  1.4716e-01],\n",
      "         [ 1.2757e-01, -1.0303e-01,  1.0982e-01, -1.0791e-02],\n",
      "         [ 7.5762e-02, -1.9120e-01,  1.6330e-01,  1.1593e-01]],\n",
      "\n",
      "        [[-4.1688e-01,  4.4083e-01,  3.2840e-01, -1.0276e-01],\n",
      "         [ 1.3058e+00,  2.3149e-01,  9.8736e-01, -7.4439e-02],\n",
      "         [-9.4370e-03, -1.6743e-02,  1.0003e-01, -2.7676e-02],\n",
      "         [ 8.5265e-02, -3.5989e-01, -1.7615e-01,  4.4453e-02],\n",
      "         [ 5.6026e-01,  1.5939e-02,  4.5132e-01,  9.0970e-02]],\n",
      "\n",
      "        [[-2.2787e-01, -8.4086e-01, -2.4995e-01,  2.4527e-01],\n",
      "         [-3.2163e-01,  3.4151e-02,  2.0699e-01, -2.3826e-02],\n",
      "         [-2.4009e-01,  1.8686e-01,  2.6624e-01,  1.2009e-01],\n",
      "         [-2.1495e-01,  2.4743e-01,  2.1956e-01, -1.1208e-02],\n",
      "         [ 1.5815e-01,  4.2181e-01,  6.3258e-01,  8.4985e-02]]],\n",
      "       grad_fn=<BmmBackward0>), shape: torch.Size([4, 5, 4])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T07:53:28.652153Z",
     "start_time": "2025-09-22T07:53:28.640136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, dim_in, dim_qk, dim_v, dim_out, num_heads, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.W_q = nn.ModuleList([nn.Linear(dim_in, dim_qk, bias=False) for _ in range(num_heads)])\n",
    "        self.W_k = nn.ModuleList([nn.Linear(dim_in, dim_qk, bias=False) for _ in range(num_heads)])\n",
    "        self.W_v = nn.ModuleList([nn.Linear(dim_in, dim_v, bias=False) for _ in range(num_heads)])\n",
    "\n",
    "        self.W_out = nn.Linear(dim_v * num_heads, dim_out, bias=False)\n",
    "\n",
    "        self.attention = Attention()\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        V = []\n",
    "        for W_q, W_k, W_v in zip(self.W_q, self.W_k, self.W_v):\n",
    "            v_head = self.attention(W_q(x), W_k(x), W_v(x), mask=mask)\n",
    "            V.append(v_head)\n",
    "\n",
    "        return self.W_out(torch.concat(V, dim=-1))\n",
    "\n",
    "mha = MultiHeadAttention(\n",
    "    dim_in=8,\n",
    "    dim_qk=6,\n",
    "    dim_v=4,\n",
    "    dim_out=10,\n",
    "    num_heads=4,\n",
    ")\n",
    "\n",
    "sample_x = torch.randn(4, 5, 8)\n",
    "result = mha(sample_x)\n",
    "print(f\"result: {result}, shape: {result.shape}\")"
   ],
   "id": "75e491eebd038209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: tensor([[[-0.1973, -0.1278,  0.2358, -0.0330, -0.2448,  0.2155,  0.1877,\n",
      "          -0.1923, -0.2080, -0.1492],\n",
      "         [-0.2029, -0.0292,  0.1893,  0.0013, -0.2249,  0.1541,  0.0822,\n",
      "          -0.1970, -0.1284, -0.1180],\n",
      "         [-0.2180, -0.0475,  0.1951,  0.0218, -0.2099,  0.1252,  0.0395,\n",
      "          -0.2133, -0.1186, -0.0796],\n",
      "         [-0.2627, -0.1205,  0.1993, -0.0384, -0.2393,  0.1813,  0.2444,\n",
      "          -0.2064, -0.1890, -0.1699],\n",
      "         [-0.2357, -0.1068,  0.2056, -0.0311, -0.2253,  0.1593,  0.2056,\n",
      "          -0.2058, -0.1699, -0.1482]],\n",
      "\n",
      "        [[-0.0796,  0.1242, -0.0150, -0.0749,  0.1168, -0.1112, -0.1272,\n",
      "          -0.0982,  0.2553, -0.0765],\n",
      "         [ 0.1006,  0.0687, -0.0159,  0.0485,  0.0024,  0.1043, -0.1007,\n",
      "          -0.0301, -0.0337,  0.0368],\n",
      "         [ 0.0053,  0.1152, -0.0302, -0.0096,  0.0564, -0.0109, -0.1370,\n",
      "          -0.0412,  0.1183, -0.0190],\n",
      "         [ 0.0948,  0.1316, -0.0693,  0.0073,  0.1275,  0.0481, -0.1298,\n",
      "          -0.1041,  0.0932, -0.0397],\n",
      "         [ 0.0678, -0.0140,  0.1008,  0.0064, -0.0351,  0.0553, -0.0665,\n",
      "          -0.0611, -0.0038,  0.0241]],\n",
      "\n",
      "        [[ 0.2284, -0.1301, -0.0469, -0.0674,  0.0212,  0.1510, -0.0014,\n",
      "          -0.0675, -0.0810,  0.0425],\n",
      "         [ 0.1960, -0.1693,  0.0030, -0.0101, -0.0067,  0.1098,  0.0431,\n",
      "          -0.0169, -0.1740,  0.0810],\n",
      "         [ 0.2059, -0.1448, -0.0555, -0.0522, -0.0188,  0.1262,  0.0504,\n",
      "          -0.0243, -0.1333,  0.0693],\n",
      "         [ 0.2027, -0.1456, -0.0744, -0.0637, -0.0376,  0.1809,  0.0562,\n",
      "          -0.0527, -0.1429,  0.0661],\n",
      "         [ 0.2195, -0.1538, -0.0357, -0.0147, -0.0283,  0.1588,  0.0344,\n",
      "          -0.0230, -0.1798,  0.0699]],\n",
      "\n",
      "        [[-0.1039,  0.2686, -0.0727, -0.1016,  0.0155, -0.1660, -0.1427,\n",
      "          -0.0295,  0.2133,  0.0477],\n",
      "         [-0.3012,  0.1007,  0.0165, -0.0522, -0.0702, -0.0951,  0.0961,\n",
      "           0.0336,  0.1151, -0.0307],\n",
      "         [-0.4119,  0.1484, -0.0754, -0.1357,  0.0438, -0.3217,  0.1083,\n",
      "          -0.0552,  0.3192, -0.0022],\n",
      "         [-0.2744,  0.0063,  0.0713, -0.1627, -0.1733, -0.0776,  0.1949,\n",
      "          -0.0337,  0.1437, -0.0821],\n",
      "         [-0.1688,  0.1998,  0.0390, -0.0891, -0.0321, -0.1340, -0.0768,\n",
      "           0.0287,  0.1830,  0.0019]]], grad_fn=<UnsafeViewBackward0>), shape: torch.Size([4, 5, 10])\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T07:11:05.611812Z",
     "start_time": "2025-09-22T07:11:05.589816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, dim_in, dim_qk, dim_v, num_heads, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.mha = MultiHeadAttention(\n",
    "            dim_in=dim_in,\n",
    "            dim_qk=dim_qk,\n",
    "            dim_v=dim_v,\n",
    "            dim_out=dim_in,\n",
    "            num_heads=num_heads,\n",
    "        )\n",
    "\n",
    "        self.mha_norm = nn.LayerNorm(dim_in)\n",
    "        self.activation = nn.GELU()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim_in, dim_in),\n",
    "            self.activation,\n",
    "            nn.Linear(dim_in, dim_in)\n",
    "        )\n",
    "        self.ff_norm = nn.LayerNorm(dim_in)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mha_out = self.mha_norm(self.mha(x)) + x\n",
    "        return self.ff_norm(self.ffn(mha_out)) + mha_out\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, dim_in, dim_qk, dim_v, num_heads, num_layers, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        layers = [TransformerEncoderLayer(dim_in=dim_in, dim_qk=dim_qk, dim_v=dim_v, num_heads=num_heads) for _ in range(num_layers)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "model = TransformerEncoder(\n",
    "    dim_in=8,\n",
    "    dim_qk=6,\n",
    "    dim_v=4,\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    ")\n",
    "\n",
    "sample_x = torch.randn(4, 5, 8)\n",
    "result = model(sample_x)\n",
    "print(f\"shape: {result.shape}, result: {result}\")"
   ],
   "id": "da41fbf2e418cc5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([4, 5, 8]), result: tensor([[[-0.3201,  0.0625,  1.6362,  3.5891, -0.1413, -1.2206, -3.2086,\n",
      "           1.0505],\n",
      "         [ 1.5041, -1.1012,  2.5851,  5.8168, -1.7879, -2.2085, -4.2433,\n",
      "           0.0286],\n",
      "         [ 1.3578, -0.3948,  2.2239,  4.9473, -2.4554, -0.6486, -3.6839,\n",
      "          -2.6097],\n",
      "         [-0.6036, -1.3961, -1.3277,  4.9567,  0.5778, -0.3719, -5.2545,\n",
      "           3.0133],\n",
      "         [-0.6930, -0.3979, -1.5184,  5.1135, -0.1629,  0.2616, -6.4386,\n",
      "           1.7458]],\n",
      "\n",
      "        [[-1.9933,  0.2171,  1.4529,  4.4601, -0.3574, -0.3835, -3.5845,\n",
      "           0.9353],\n",
      "         [ 0.6849, -0.4494,  2.7661,  3.8220, -3.2947,  0.2268, -3.2978,\n",
      "          -2.3724],\n",
      "         [ 0.3149, -2.2079, -0.2901,  5.0354, -0.7963, -0.1709, -6.6625,\n",
      "           2.0712],\n",
      "         [ 1.7548, -1.8341,  1.8345,  4.6398, -2.3439,  0.8804, -4.2612,\n",
      "          -1.5792],\n",
      "         [ 0.6798,  0.6331,  2.6075,  3.2651, -3.4048, -0.1269, -4.0909,\n",
      "          -1.3368]],\n",
      "\n",
      "        [[-1.9374, -0.7035,  1.0690,  1.3978, -1.9009, -0.1401, -2.2731,\n",
      "          -0.3018],\n",
      "         [-1.8971,  0.0785,  1.4216,  2.9788, -0.7848, -0.0413, -3.3762,\n",
      "           0.2755],\n",
      "         [-0.2840, -0.3215,  2.9066,  3.9721, -1.6569,  0.9151, -5.4959,\n",
      "          -2.7276],\n",
      "         [ 0.2443,  1.2469,  2.4715,  2.7979, -1.2785,  0.0254, -4.7023,\n",
      "          -3.0132],\n",
      "         [-3.4283,  0.3615,  0.4423,  4.6756, -1.6840,  1.5547, -5.4629,\n",
      "           0.6818]],\n",
      "\n",
      "        [[ 2.7962, -1.5993,  1.6869,  2.7357, -4.3324,  0.2796, -5.5551,\n",
      "           1.1488],\n",
      "         [ 0.8869, -1.0929,  1.1423,  3.0433, -3.0803,  1.2917, -4.9723,\n",
      "           1.9478],\n",
      "         [ 0.0875, -1.2322,  2.5586,  3.9994, -2.2348,  1.4665, -3.1891,\n",
      "          -0.4310],\n",
      "         [ 3.8680, -2.3878,  1.9107,  2.2689, -4.6149,  1.7517, -4.9300,\n",
      "          -0.5503],\n",
      "         [ 3.4421, -2.4411,  2.0521,  1.5310, -3.8770,  1.0879, -4.0052,\n",
      "          -0.3452]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T07:53:33.804300Z",
     "start_time": "2025-09-22T07:53:33.779876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, dim_in, dim_qk, dim_v, num_heads, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.masked_mha = MultiHeadAttention(\n",
    "            dim_in=dim_in,\n",
    "            dim_qk=dim_qk,\n",
    "            dim_v=dim_v,\n",
    "            dim_out=dim_in,\n",
    "            num_heads=num_heads,\n",
    "        )\n",
    "        self.masked_mha_norm = nn.LayerNorm(dim_in)\n",
    "\n",
    "        self.mha = MultiHeadAttention(\n",
    "            dim_in=dim_in,\n",
    "            dim_qk=dim_qk,\n",
    "            dim_v=dim_v,\n",
    "            dim_out=dim_in,\n",
    "            num_heads=num_heads,\n",
    "        )\n",
    "        self.mha_norm = nn.LayerNorm(dim_in)\n",
    "\n",
    "        self.activation = nn.GELU()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim_in, dim_in),\n",
    "            self.activation,\n",
    "            nn.Linear(dim_in, dim_in)\n",
    "        )\n",
    "        self.ff_norm = nn.LayerNorm(dim_in)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        masked_mha_out = self.masked_mha_norm(self.masked_mha(x, mask=mask)) + x\n",
    "        mha_out = self.mha_norm(self.mha(masked_mha_out)) + masked_mha_out\n",
    "        return self.ff_norm(self.ffn(mha_out)) + mha_out\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, dim_in, dim_qk, dim_v, num_heads, num_layers, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        layers = [TransformerDecoderLayer(dim_in=dim_in, dim_qk=dim_qk, dim_v=dim_v, num_heads=num_heads) for _ in range(num_layers)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x\n",
    "\n",
    "model = TransformerDecoder(\n",
    "    dim_in=8,\n",
    "    dim_qk=6,\n",
    "    dim_v=4,\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    ")\n",
    "\n",
    "sample_x = torch.randn(4, 5, 8)\n",
    "result = model(sample_x, mask=causal_mask(sample_x.shape[-2]))\n",
    "print(f\"shape: {result.shape}, result: {result}\")"
   ],
   "id": "7064495d96a308f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([4, 5, 8]), result: tensor([[[-2.1156,  0.3588, -0.1507,  3.9490, -0.3605, -0.3159, -1.5909,\n",
      "          -4.3717],\n",
      "         [ 0.2610, -2.9844,  3.2863,  3.9364,  2.0252, -1.0371, -4.7748,\n",
      "          -1.9584],\n",
      "         [ 2.7874, -2.9923,  3.7135,  4.7617,  4.1527, -1.1137, -4.7065,\n",
      "          -3.9936],\n",
      "         [ 3.7710, -5.5868,  1.4442,  3.5567,  4.2420,  0.3629, -3.0979,\n",
      "          -3.2620],\n",
      "         [ 2.4560, -6.7225,  3.0729,  3.6182,  4.5079, -0.8883, -3.1035,\n",
      "          -4.3668]],\n",
      "\n",
      "        [[ 0.0565, -2.5177,  4.2840,  4.7264, -1.3165,  0.0393,  0.7770,\n",
      "          -4.8648],\n",
      "         [ 2.0736, -5.3310,  5.5753,  2.2674,  1.2505, -5.0134, -1.5506,\n",
      "          -0.4883],\n",
      "         [ 4.6582, -2.4041,  6.4920,  4.5495, -1.9759, -4.1674, -4.6975,\n",
      "          -4.9908],\n",
      "         [ 3.5562, -1.6611,  5.5223,  5.5378, -0.5072, -3.8585, -4.5194,\n",
      "          -5.0245],\n",
      "         [ 5.5365, -2.4497,  4.8449,  4.3338,  1.4866, -2.8502, -3.9409,\n",
      "          -5.0749]],\n",
      "\n",
      "        [[ 2.6910, -4.1993,  2.8822, -0.3716,  5.6385,  0.3238,  0.3245,\n",
      "          -3.8130],\n",
      "         [ 0.9911, -1.7471,  0.8164, -3.0324,  1.5557,  4.2400,  0.4983,\n",
      "          -5.6618],\n",
      "         [ 1.2359, -2.8841,  0.9927, -2.9946,  1.5823,  4.8088,  1.4684,\n",
      "          -3.8226],\n",
      "         [ 1.5145, -2.8645, -0.4592, -1.9412,  2.8909,  0.8307,  3.0090,\n",
      "          -2.0570],\n",
      "         [ 3.8455, -4.6036,  2.9664, -0.5105,  6.3938,  2.9659, -0.4164,\n",
      "          -7.3853]],\n",
      "\n",
      "        [[ 3.3846, -5.1208,  4.6921, -6.1395,  6.3719,  0.6029,  2.9637,\n",
      "          -9.8412],\n",
      "         [ 3.1776, -3.5446,  2.0814, -5.4501,  7.9425, -0.7388,  4.9507,\n",
      "          -7.1180],\n",
      "         [ 0.4229, -4.6246,  2.2408, -1.5371,  5.5275, -1.7414,  3.8195,\n",
      "          -4.8605],\n",
      "         [ 2.0218, -4.4040, -0.5940, -5.2149,  5.8274,  2.5944,  4.3563,\n",
      "          -4.2782],\n",
      "         [ 2.1771, -3.8848,  3.5905, -6.2847,  5.9797,  1.1602,  4.4632,\n",
      "          -7.5962]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e54266d49c0cec8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
